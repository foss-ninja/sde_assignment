"""
Airflow DAG to generate a report with the number of daily lessons completed by users
in the last year.

The report is generated by extracting user and lessons data from PostgreSQL and MySQL
databases, respectively. The data is then transformed into the required format and
saved to a CSV file.

The report is then uploaded to an S3 bucket and a public URL is generated and sent
to the recipient email address.

"""

from datetime import datetime, timedelta

from airflow import DAG
from airflow.operators.python import PythonOperator
from config import settings
from utils.aws_utils import get_boto_client, upload_file_to_s3
from utils.core_utils import generate_csv_report, send_report_on_mail
from utils.extract_data_utils import extract_mysql_data, extract_postgres_data
from utils.transform_data_utils import transform_data

# Define default arguments for the DAG
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "start_date": datetime(2024, 9, 14),
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=5),
}

# Create the DAG
with DAG(
    dag_id="daily_lessions_report_dag",
    default_args=default_args,
    description="DAG to extract users and lessons data from PostgreSQL and MySQL, "
    "transform the data, and generate a custom report with the number "
    "of daily lessons completed by users in the last year, and save "
    "the report to a CSV file",
    schedule_interval=timedelta(days=1),  # Run every day
    catchup=False,
) as dag:
    # Task 1: Extract users data from PostgreSQL
    def extract_users_data(ti):
        ti.xcom_push(key="users_data", value=extract_postgres_data())

    extract_users_data_task = PythonOperator(
        task_id="extract_users_data",
        python_callable=extract_users_data,
    )

    # Task 2: Extract lessons data from MySQL
    def extract_lessons_data(ti):
        ti.xcom_push(key="lessons_data", value=extract_mysql_data())

    extract_lessons_data_task = PythonOperator(
        task_id="extract_lessons_data",
        python_callable=extract_lessons_data,
    )

    # Task 3: Transform data
    def format_data(ti):
        # Here ti is a TaskInstance object, which provides access to the
        # context of the task instance, including the task_id, dag_id,
        # and execution_date. The xcom_pull method allows us to pull
        # XCOM values from other tasks in the same DAG.
        users_data = ti.xcom_pull(task_ids="extract_users_data", key="users_data")
        lessons_data = ti.xcom_pull(task_ids="extract_lessons_data", key="lessons_data")
        ti.xcom_push(key="report_data", value=transform_data(users_data, lessons_data))

    transform_data_task = PythonOperator(
        task_id="transform_data",
        python_callable=format_data,
    )

    # Task 4: Generate the CSV report
    def generate_report(ti):
        report_data = ti.xcom_pull(task_ids="transform_data", key="report_data")
        file_name = f"{settings.report_file_name}{datetime.now().strftime('-%Y-%m-%d_%H-%M-%S')}.csv"
        generate_csv_report(
            report_df=report_data, file_name=file_name
        )
        ti.xcom_push(key="file_name", value=file_name)

    generate_csv_report_task = PythonOperator(
        task_id="generate_csv_report",
        python_callable=generate_report,
    )

    # Task 5: Upload report to S3
    def upload_report(ti):
        file_name = ti.xcom_pull(task_ids="generate_csv_report", key="file_name")
        upload_file_to_s3(
            s3_client=get_boto_client("s3"),
            file_name=file_name,
        )

    upload_report_to_s3_task = PythonOperator(
        task_id="upload_report_to_s3",
        python_callable=upload_report,
    )

    # Task 6: Send report via email
    def send_report(ti):
        file_name = ti.xcom_pull(task_ids="generate_csv_report", key="file_name")
        send_report_on_mail(file_name=file_name)

    send_report_on_mail_task = PythonOperator(
        task_id="send_report_on_email",
        python_callable=send_report,
    )

    # Define task dependencies
    # extract_users_data_task >> extract_lessons_data_task >> transform_data_task >> generate_csv_report_task >> upload_report_to_s3_task >> send_report_on_mail_task
    [extract_users_data_task, extract_lessons_data_task] >> transform_data_task >> generate_csv_report_task >> [upload_report_to_s3_task, send_report_on_mail_task]
